# -*- coding: utf-8 -*-
"""momentoDeRetroalimentacionM2Analisis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nYYQkhGGR_HQdxVIvG85HBXOoW4lb3tI

#  Análisis y Reporte sobre el desempeño del modelo. (Portafolio Análisis)
"""

'''
Momento de Retroalimentación: Módulo 2 Uso de framework o biblioteca de 
aprendizaje máquina para la implementación de una solución. 
(Portafolio Implementación)

Jorge Chávez Badillo A01749448

18-09-2022
'''

# Importación de Librerías 
import graphviz
import numpy as np 
import pandas as pd
import seaborn as sns
from sklearn import tree
from sklearn import metrics
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from mlxtend.plotting import plot_learning_curves
from sklearn.model_selection import train_test_split

"""## Lectura de Datos"""

# Dataset Breast Cancer
df = pd.read_csv('/content/breast_cancer.csv')
df.drop(columns = ['Unnamed: 0'], inplace=True)
df

"""## Entendimiento de Datos

### Verificación de los Tipos de Datos
"""

'''
Observar los tipos de datos del dataset
'''

df.info()

"""### Búsqueda de Valores Nulos"""

'''
Se genera una tabla donde se obtiene el porcentage de valores nulos en 
el dataset para poder decidir si se hace o no una limpieza de datos para 
procesar los datos que estén incompletos.
'''

total = df.isnull().sum().sort_values(ascending=False)
percent_1 = df.isnull().sum() / df.isnull().count()*100
percent_2 = (round(percent_1, 1)).sort_values(ascending=False)
missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])
missing_data.head()

"""### Análisis Estadístico """

'''
Se obtienen estadísticos generales sobre el dataset para poder 
observar el comportamiento
'''

df.describe()

# Comparación de Valores Benignos (1) y Malignos (0)
sns.countplot(df['status'], label="Count", palette = 'Set2').set(title = 'Valores Benignos (1) vs Malignos (0)')
plt.show()

sns.relplot(data = df, x = 'mean radius', y = 'mean concavity', hue = 'status').set(title = 'Radio vs Concavidad')

sns.relplot(data = df, x = 'mean perimeter', y = 'mean area', hue = 'status').set(title = 'Perímetro vs Área')

"""### Búsqueda de Correlaciones"""

# Matriz de Correlación
correlationMatrix = df.corr()
correlationMatrix.style.background_gradient(cmap='GnBu')

"""## Limpieza y Preparación de los Datos

### Separación del Dataset en Training y Test
"""

'''Ya que no existen valores nulos, solo es necesario preparar los datos para 
ser procesados por el modelo, separar en valores de entrenamiento y pruebas, 
además del escalamiento de los valores de x'''

x = df.copy().drop(columns = ['status'])
y = df['status']

# Training y Testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)
x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size = 0.20, random_state = 0)

"""### Escalamiento Datos de X"""

# Escalamiento de x
escalador = StandardScaler()
x_train = escalador.fit_transform(x_train)
x_test = escalador.transform(x_test)
x_val = escalador.transform(x_val)

"""## Modelo Elegido

### Árboles de Decisión (Decision Tree)

### Pruebas con Diferentes Parámetros
"""

# Configuración del Modelo de Árbol de Decisión

# Árbol 1
decisionTree1 = DecisionTreeClassifier(random_state = 0, 
                                       max_depth = 3)
decisionTree1.fit(x_train, y_train)
print('=' * 10, 'Árbol 1', '=' * 10)
print('Score: ', decisionTree1.score(x_train, y_train))
print()

# Árbol 2
decisionTree2 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6)
decisionTree2.fit(x_train, y_train)
print('=' * 10, 'Árbol 2', '=' * 10)
print('Score: ', decisionTree2.score(x_train, y_train))
print()

# Árbol 3
decisionTree3 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6, 
                                       min_samples_split = 4,
                                       min_impurity_decrease=0.01)
decisionTree3.fit(x_train, y_train)
print('=' * 10, 'Árbol 3', '=' * 10)
print('Score: ', decisionTree3.score(x_train, y_train))
print()

# Árbol 4
decisionTree4 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 4,
                                       min_impurity_decrease=0.01)
decisionTree4.fit(x_train, y_train)
print('=' * 10, 'Árbol 4', '=' * 10)
print('Score: ', decisionTree4.score(x_train, y_train))
print()

# Árbol 5
decisionTree5 = DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6,
                                       min_samples_leaf=8,
                                       min_impurity_decrease=0.02)
decisionTree5.fit(x_train, y_train)
print('=' * 10, 'Árbol 5', '=' * 10)
print('Score: ', decisionTree5.score(x_train, y_train))
print()

'''
De acuerdo a los scores obtenidos, tenemos que los parámetros utilizados en
en el árbol número dos tienen un valor más alto, por ello, procedemos a obtener
el mejor valor de alpha para posteriormente hacer las predicciones. 
'''

decisionTree2.get_params()

"""### Búsqueda del Mejor Valor de Alpha"""

# Obtención de los valores de alpha para encontrar el que tenga mejor desempeño
pruning_data = decisionTree2.cost_complexity_pruning_path(x_train, y_train)
alphaValues = pruning_data.ccp_alphas
impurityValues = pruning_data.impurities
print('Alpha Values: ', alphaValues)

'''
Creación de árboles con los valores de alpha para decidir 
el que tenga un mejor desempeño.
'''

allTrees = []

for thisAlpha in alphaValues:
  thisTree=tree.DecisionTreeClassifier(criterion = 'entropy', 
                                       random_state = 0, 
                                       max_depth = 6, 
                                       ccp_alpha = thisAlpha)
  thisTree.fit(x_train, y_train)
  allTrees.append(thisTree)

# Comparación de desempeño para cada árbol 
allTrainScores = []
allTestScores = []
allValScores = []

for thisTree in allTrees:
  allTrainScores.append(thisTree.score(x_train, y_train))
  allTestScores.append(thisTree.score(x_test, y_test))
  allValScores.append(thisTree.score(x_val, y_val))

print('Alpha Values: ', alphaValues)
print('Trainning Scores: ', allTrainScores)
print('Testing Scores: ', allTestScores)
print('Validation Scores: ', allValScores)

plt.figure(figsize = (10, 6))
plt.grid()
plt.plot(alphaValues, allTrainScores, linestyle = 'dotted', marker = 'o')
plt.plot(alphaValues, allTestScores, linestyle = 'dotted', marker = 'o')
plt.plot(alphaValues, allValScores, linestyle = 'dotted', marker = 'o')
plt.legend(['Train', 'Test', 'Validation'])
plt.title('Desempeño')
plt.xlabel('Alpha')
plt.ylabel('Score')
#plt.xlim(-0.1, 0.3)
plt.ylim(0.3, 1.2)
plt.show()

'''
Como podemos observar, el valor de alpha cuando se encuentra entre 0.0 y 0.015 
tanto para test y train, da como resultado mejores scores, por ello se elegirá
el alpha que se encuentre en ese rango para tener predicciones más acertadas. 
'''

finalTree = DecisionTreeClassifier(criterion = 'entropy', 
                                   random_state = 0,
                                   max_depth = 6, 
                                   ccp_alpha = 0.00910266)
finalTree.fit(x_train, y_train)
print('=' * 10, 'Árbol Final', '=' * 10)
print('Score: ', finalTree.score(x_train, y_train))

"""### Visualización del Árbol de Decisión"""

print(tree.export_text(finalTree))

myTreeData = tree.export_graphviz(finalTree)
graphData = graphviz.Source(myTreeData)
graphData

feature_names = x.columns
class_names = ['Maligno', 'Benigno']
finalTreeData = tree.export_graphviz(finalTree, 
                                     feature_names = feature_names,
                                     class_names = class_names, 
                                     leaves_parallel = True,
                                     filled = True, 
                                     proportion = True, 
                                     rotate = False)
graphData = graphviz. Source(finalTreeData)
graphData

"""### Predicciones Usando el Mejor Modelo"""

# Prediccion de los valores usando el árbol de decisión 
prediccion_test = finalTree.predict(x_test)
prediccion_val = finalTree.predict(x_val)
# Valores reales de y
y_test = np.array(y_test)
y_val = np.array(y_val)
print('*' * 10, 'Test', '*' * 10)
print('=' * 80)
print('Valores De Entrada: ')
print(x_test)
print('=' * 80)
print('Valores Reales: ')
print(y_test)
print('=' * 80)
print('Predicción: ')
print(prediccion_test)

print('*' * 10, 'Validation', '*' * 10)
print('=' * 80)
print('Valores De Entrada: ')
print(x_val)
print('=' * 80)
print('Valores Reales: ')
print(y_val)
print('=' * 80)
print('Predicción: ')
print(prediccion_val)

def statusPrediction(row):
  row.to_frame()
  real = row['real values']
  pred = row['prediction']
  if real == pred:
    return "Acertado"
  else:
    return "No Acertado"

df_x_test = pd.DataFrame(x_test)
column_name = list(df.columns)[:-1]
df_x_test.columns = column_name
df_x_test['real values'] = y_test
df_x_test['prediction'] = prediccion_test
df_x_test['status'] = df_x_test.apply(lambda row: statusPrediction(row), axis=1)
df_x_test

df_x_val = pd.DataFrame(x_val)
column_name = list(df.columns)[:-1]
df_x_val.columns = column_name
df_x_val['real values'] = y_val
df_x_val['prediction'] = prediccion_val
df_x_val['status'] = df_x_val.apply(lambda row: statusPrediction(row), axis=1)
df_x_val

# Probabilidad 
print(finalTree.predict_proba(x_test))

"""### Métricas"""

# Classification Report Test
print(metrics.classification_report(y_test, prediccion_test, 
                                    target_names = ['Maligno', 'Benigno']))

# Classification Report Validation
print(metrics.classification_report(y_val, prediccion_val, 
                                    target_names = ['Maligno', 'Benigno']))

# Test
print('Accuracy Score Test: ', metrics.accuracy_score(y_test, prediccion_test))
print('Precision Score Test: ', metrics.precision_score(y_test, prediccion_test))
print('Recall Score Test: ', metrics.recall_score(y_test, prediccion_test))

# Validation
print('Accuracy Score Test: ', metrics.accuracy_score(y_val, prediccion_val))
print('Precision Score Test: ', metrics.precision_score(y_val, prediccion_val))
print('Recall Score Test: ', metrics.recall_score(y_val, prediccion_val))

# Test
print('Matriz de Confusión: ')
confusion_matrix_test = metrics.confusion_matrix(y_test, prediccion_test, labels = [0, 1])
print(confusion_matrix_test)

ax = sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues')
ax.set_title('Matriz de Confusión Test\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values');
## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

# Validation
print('Matriz de Confusión: ')
confusion_matrix_val = metrics.confusion_matrix(y_val, prediccion_val, labels = [0, 1])
print(confusion_matrix_val)

ax = sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues')
ax.set_title('Matriz de Confusión Validation\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values');
## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

feature_importance = pd.DataFrame({'feature_names': feature_names, 'feature_importance': finalTree.feature_importances_})
feature_importance.sort_values(inplace = True, by = 'feature_importance', ascending = False)
feature_importance

feature_importance.plot.bar().set(title = 'Feature Importance')

plot_learning_curves(x_train, y_train, x_test, y_test, finalTree)
plt.title('Train vs Test')
plt.legend(['Training Set', 'Testing Set'])
plt.ylim(-0.2, 0.2)
plt.show()

plot_learning_curves(x_train, y_train, x_val, y_val, finalTree)
plt.title('Train vs Validation')
plt.legend(['Training Set', 'Validation Set'])
plt.ylim(-0.2, 0.2)
plt.show()

print('Mean Squared Error Test: ', metrics.mean_squared_error(y_test, prediccion_test))
print('Mean Absolute Error Test: ', metrics.mean_absolute_error(y_test, prediccion_test))
print('Mean Squared Error Validation: ', metrics.mean_squared_error(y_val, prediccion_val))
print('Mean Absolute Error Validation: ', metrics.mean_absolute_error(y_val, prediccion_val))

'''
Cómo se puede observar en los gráficos anteriores, con el modelo finalTree se 
llegó a el fit deseado gracias a los valores que fueron elegidos para cada 
uno de los parámetros del árbol de decisión. 
'''